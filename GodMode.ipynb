{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GodMode.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/v1an1/Remote-sensing-image-classification/blob/master/GodMode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSgzx5ocxYEg",
        "colab_type": "text"
      },
      "source": [
        "Mount your drive containing 'src.zip'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gW0fy3ava-k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "54df4481-5638-4679-e18c-31d1c6bd84fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ND0fAC2Gx0Zv",
        "colab_type": "text"
      },
      "source": [
        "Unzip the folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tePfCDjvjjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip '/content/drive/My Drive/src.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUu91uD8x2mG",
        "colab_type": "text"
      },
      "source": [
        "Copy the model file in current directory for usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pyLW16JvY_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"/content/src/utils_jnb.py\" ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZu4HqOEt5aP",
        "colab_type": "code",
        "outputId": "39d7103b-aeab-4545-d225-21113698f8ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch \n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from utils_jnb import *\n",
        "\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb30a6401d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1kqZz_v1T2y",
        "colab_type": "code",
        "outputId": "748f4701-56ea-47f5-f02f-a1e026beceb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiVw_drJsMwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "directory = \"/content/src\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2sgdxa1sNbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 3\n",
        "\n",
        "vgg19 = models.vgg19_bn(pretrained=True)\n",
        "# Freeze model parameters\n",
        "# Same for all\n",
        "for param in vgg19.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "vgg19.classifier = nn.Sequential(nn.Linear(25088, 4096),\n",
        "nn.ReLU(),\n",
        "nn.Dropout(0.4),\n",
        "nn.Linear(4096, 1024),\n",
        "nn.ReLU(),\n",
        "nn.Dropout(0.4),\n",
        "nn.Linear(1024, num_classes),\n",
        "nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2X4kzWXv3b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Optimizer and Loss Function\n",
        "lossFunc = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(vgg19.parameters(), lr=1e-2)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "expLrScheduler = lr_scheduler.StepLR(optimizer, step_size=6, gamma=0.1)\n",
        "\n",
        "vgg19.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-Sg3anS0PTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "summary(vgg19, input_size=(3, 224, 224), batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npNkQm7W0Pr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6b37d19c-e5f7-46a4-d941-6205cde6bb1f"
      },
      "source": [
        "history = trainValid(vgg19, lossFunc, optimizer, epochs=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2\n",
            "Batch number: 000, Training: Loss: 1.1047, Accuracy: 0.2500\n",
            "Batch number: 001, Training: Loss: 707.6970, Accuracy: 0.3750\n",
            "Batch number: 002, Training: Loss: 358.7710, Accuracy: 0.3750\n",
            "Batch number: 003, Training: Loss: 299.7534, Accuracy: 0.3125\n",
            "Batch number: 004, Training: Loss: 38.7415, Accuracy: 0.6250\n",
            "Batch number: 005, Training: Loss: 57.8354, Accuracy: 0.6250\n",
            "Batch number: 006, Training: Loss: 28.4534, Accuracy: 0.6250\n",
            "Batch number: 007, Training: Loss: 51.6681, Accuracy: 0.2812\n",
            "Batch number: 008, Training: Loss: 6.0232, Accuracy: 0.8125\n",
            "Batch number: 009, Training: Loss: 6.4400, Accuracy: 0.5938\n",
            "Batch number: 010, Training: Loss: 3.1276, Accuracy: 0.5938\n",
            "Batch number: 011, Training: Loss: 8.1860, Accuracy: 0.6250\n",
            "Batch number: 012, Training: Loss: 5.8234, Accuracy: 0.6250\n",
            "Batch number: 013, Training: Loss: 3.7581, Accuracy: 0.6250\n",
            "Batch number: 014, Training: Loss: 7.5087, Accuracy: 0.5938\n",
            "Batch number: 015, Training: Loss: 2.1335, Accuracy: 0.7812\n",
            "Batch number: 016, Training: Loss: 6.0246, Accuracy: 0.7812\n",
            "Batch number: 017, Training: Loss: 10.3886, Accuracy: 0.5938\n",
            "Batch number: 018, Training: Loss: 1.3148, Accuracy: 0.8125\n",
            "Batch number: 019, Training: Loss: 0.7475, Accuracy: 0.8438\n",
            "Batch number: 020, Training: Loss: 3.6602, Accuracy: 0.6250\n",
            "Batch number: 021, Training: Loss: 1.2082, Accuracy: 0.8438\n",
            "Batch number: 022, Training: Loss: 2.8234, Accuracy: 0.7500\n",
            "Batch number: 023, Training: Loss: 1.2475, Accuracy: 0.8438\n",
            "Batch number: 024, Training: Loss: 1.0100, Accuracy: 0.8750\n",
            "Batch number: 025, Training: Loss: 0.7040, Accuracy: 0.8750\n",
            "Batch number: 026, Training: Loss: 2.2386, Accuracy: 0.8125\n",
            "Batch number: 027, Training: Loss: 3.8356, Accuracy: 0.7812\n",
            "Batch number: 028, Training: Loss: 0.7014, Accuracy: 0.8750\n",
            "Batch number: 029, Training: Loss: 0.2276, Accuracy: 0.9688\n",
            "Batch number: 030, Training: Loss: 0.9494, Accuracy: 0.8750\n",
            "Batch number: 031, Training: Loss: 3.2955, Accuracy: 0.6562\n",
            "Batch number: 032, Training: Loss: 0.4859, Accuracy: 0.9375\n",
            "Batch number: 033, Training: Loss: 0.5579, Accuracy: 0.8750\n",
            "Batch number: 034, Training: Loss: 1.7918, Accuracy: 0.8438\n",
            "Batch number: 035, Training: Loss: 2.7192, Accuracy: 0.8125\n",
            "Batch number: 036, Training: Loss: 0.2933, Accuracy: 0.9062\n",
            "Batch number: 037, Training: Loss: 0.7013, Accuracy: 0.8750\n",
            "Batch number: 038, Training: Loss: 0.2525, Accuracy: 0.9688\n",
            "Batch number: 039, Training: Loss: 0.5479, Accuracy: 0.8750\n",
            "Batch number: 040, Training: Loss: 0.4574, Accuracy: 0.9062\n",
            "Batch number: 041, Training: Loss: 0.3617, Accuracy: 0.9062\n",
            "Validation Batch number: 000, Validation: Loss: 0.0005, Accuracy: 1.0000\n",
            "Validation Batch number: 001, Validation: Loss: 0.0128, Accuracy: 1.0000\n",
            "Validation Batch number: 002, Validation: Loss: 0.0009, Accuracy: 1.0000\n",
            "Validation Batch number: 003, Validation: Loss: 0.0003, Accuracy: 1.0000\n",
            "Validation Batch number: 004, Validation: Loss: 0.3563, Accuracy: 0.7500\n",
            "Validation Batch number: 005, Validation: Loss: 0.0025, Accuracy: 1.0000\n",
            "Validation Batch number: 006, Validation: Loss: 0.0389, Accuracy: 1.0000\n",
            "Validation Batch number: 007, Validation: Loss: 0.0008, Accuracy: 1.0000\n",
            "Validation Batch number: 008, Validation: Loss: 0.0005, Accuracy: 1.0000\n",
            "Validation Batch number: 009, Validation: Loss: 1.0270, Accuracy: 0.7500\n",
            "Validation Batch number: 010, Validation: Loss: 0.0001, Accuracy: 1.0000\n",
            "Validation Batch number: 011, Validation: Loss: 0.0023, Accuracy: 1.0000\n",
            "Validation Batch number: 012, Validation: Loss: 0.6161, Accuracy: 0.7500\n",
            "Validation Batch number: 013, Validation: Loss: 0.0002, Accuracy: 1.0000\n",
            "Validation Batch number: 014, Validation: Loss: 0.9576, Accuracy: 0.7500\n",
            "Validation Batch number: 015, Validation: Loss: 0.0640, Accuracy: 1.0000\n",
            "Validation Batch number: 016, Validation: Loss: 1.0051, Accuracy: 0.7500\n",
            "Validation Batch number: 017, Validation: Loss: 0.0024, Accuracy: 1.0000\n",
            "Validation Batch number: 018, Validation: Loss: 0.0000, Accuracy: 1.0000\n",
            "Validation Batch number: 019, Validation: Loss: 0.6964, Accuracy: 0.7500\n",
            "Validation Batch number: 020, Validation: Loss: 0.0534, Accuracy: 1.0000\n",
            "Validation Batch number: 021, Validation: Loss: 0.0003, Accuracy: 1.0000\n",
            "Validation Batch number: 022, Validation: Loss: 0.0000, Accuracy: 1.0000\n",
            "Validation Batch number: 023, Validation: Loss: 0.0012, Accuracy: 1.0000\n",
            "Validation Batch number: 024, Validation: Loss: 0.0538, Accuracy: 1.0000\n",
            "Validation Batch number: 025, Validation: Loss: 0.0008, Accuracy: 1.0000\n",
            "Validation Batch number: 026, Validation: Loss: 0.0052, Accuracy: 1.0000\n",
            "Validation Batch number: 027, Validation: Loss: 0.3600, Accuracy: 0.7500\n",
            "Validation Batch number: 028, Validation: Loss: 0.0000, Accuracy: 1.0000\n",
            "Validation Batch number: 029, Validation: Loss: 0.6987, Accuracy: 0.7500\n",
            "Validation Batch number: 030, Validation: Loss: 0.0018, Accuracy: 1.0000\n",
            "Validation Batch number: 031, Validation: Loss: 0.4383, Accuracy: 0.7500\n",
            "Validation Batch number: 032, Validation: Loss: 0.9694, Accuracy: 0.7500\n",
            "Validation Batch number: 033, Validation: Loss: 0.0241, Accuracy: 1.0000\n",
            "Validation Batch number: 034, Validation: Loss: 0.0000, Accuracy: 1.0000\n",
            "Validation Batch number: 035, Validation: Loss: 0.0004, Accuracy: 1.0000\n",
            "Validation Batch number: 036, Validation: Loss: 1.3360, Accuracy: 0.7500\n",
            "Epoch : 000, Training: Loss : 38.7691, Accuracy: 72.1481%\n",
            "Validation : Loss : 0.2327, Accuracy: 91.3333%, Time: 18.7991s\n",
            "model for epoch 0 saved\n",
            "Best accuracy achieved so far : 0.9133 on epoch 0\n",
            "Epoch: 2/2\n",
            "Batch number: 000, Training: Loss: 21.5399, Accuracy: 0.7500\n",
            "Batch number: 001, Training: Loss: 2.7586, Accuracy: 0.8125\n",
            "Batch number: 002, Training: Loss: 0.3700, Accuracy: 0.8750\n",
            "Batch number: 003, Training: Loss: 0.2845, Accuracy: 0.9688\n",
            "Batch number: 004, Training: Loss: 0.0051, Accuracy: 1.0000\n",
            "Batch number: 005, Training: Loss: 0.9602, Accuracy: 0.7812\n",
            "Batch number: 006, Training: Loss: 1.2467, Accuracy: 0.8125\n",
            "Batch number: 007, Training: Loss: 0.0424, Accuracy: 0.9688\n",
            "Batch number: 008, Training: Loss: 0.1441, Accuracy: 0.9688\n",
            "Batch number: 009, Training: Loss: 0.6118, Accuracy: 0.8125\n",
            "Batch number: 010, Training: Loss: 1.0851, Accuracy: 0.8125\n",
            "Batch number: 011, Training: Loss: 0.4329, Accuracy: 0.9375\n",
            "Batch number: 012, Training: Loss: 1.0093, Accuracy: 0.9062\n",
            "Batch number: 013, Training: Loss: 0.6015, Accuracy: 0.8750\n",
            "Batch number: 014, Training: Loss: 0.2214, Accuracy: 0.8750\n",
            "Batch number: 015, Training: Loss: 0.4188, Accuracy: 0.8438\n",
            "Batch number: 016, Training: Loss: 0.0624, Accuracy: 0.9688\n",
            "Batch number: 017, Training: Loss: 0.1818, Accuracy: 0.8750\n",
            "Batch number: 018, Training: Loss: 0.2628, Accuracy: 0.8750\n",
            "Batch number: 019, Training: Loss: 0.1544, Accuracy: 0.8750\n",
            "Batch number: 020, Training: Loss: 0.3260, Accuracy: 0.8438\n",
            "Batch number: 021, Training: Loss: 0.2332, Accuracy: 0.9062\n",
            "Batch number: 022, Training: Loss: 0.2813, Accuracy: 0.8750\n",
            "Batch number: 023, Training: Loss: 0.1729, Accuracy: 0.9062\n",
            "Batch number: 024, Training: Loss: 0.1326, Accuracy: 0.9062\n",
            "Batch number: 025, Training: Loss: 0.1851, Accuracy: 0.8750\n",
            "Batch number: 026, Training: Loss: 0.1414, Accuracy: 0.9375\n",
            "Batch number: 027, Training: Loss: 0.1541, Accuracy: 0.9375\n",
            "Batch number: 028, Training: Loss: 0.0694, Accuracy: 1.0000\n",
            "Batch number: 029, Training: Loss: 0.4636, Accuracy: 0.9062\n",
            "Batch number: 030, Training: Loss: 0.3487, Accuracy: 0.8750\n",
            "Batch number: 031, Training: Loss: 0.4167, Accuracy: 0.8750\n",
            "Batch number: 032, Training: Loss: 0.0433, Accuracy: 1.0000\n",
            "Batch number: 033, Training: Loss: 0.3386, Accuracy: 0.8750\n",
            "Batch number: 034, Training: Loss: 0.3014, Accuracy: 0.9062\n",
            "Batch number: 035, Training: Loss: 0.1794, Accuracy: 0.9688\n",
            "Batch number: 036, Training: Loss: 0.1290, Accuracy: 0.9375\n",
            "Batch number: 037, Training: Loss: 0.1455, Accuracy: 0.9375\n",
            "Batch number: 038, Training: Loss: 0.0506, Accuracy: 1.0000\n",
            "Batch number: 039, Training: Loss: 0.4464, Accuracy: 0.8750\n",
            "Batch number: 040, Training: Loss: 0.4125, Accuracy: 0.8750\n",
            "Batch number: 041, Training: Loss: 0.1386, Accuracy: 0.9062\n",
            "Validation Batch number: 000, Validation: Loss: 0.0580, Accuracy: 1.0000\n",
            "Validation Batch number: 001, Validation: Loss: 0.0113, Accuracy: 1.0000\n",
            "Validation Batch number: 002, Validation: Loss: 0.0172, Accuracy: 1.0000\n",
            "Validation Batch number: 003, Validation: Loss: 0.0069, Accuracy: 1.0000\n",
            "Validation Batch number: 004, Validation: Loss: 0.0213, Accuracy: 1.0000\n",
            "Validation Batch number: 005, Validation: Loss: 0.0135, Accuracy: 1.0000\n",
            "Validation Batch number: 006, Validation: Loss: 0.1039, Accuracy: 1.0000\n",
            "Validation Batch number: 007, Validation: Loss: 0.0009, Accuracy: 1.0000\n",
            "Validation Batch number: 008, Validation: Loss: 0.0105, Accuracy: 1.0000\n",
            "Validation Batch number: 009, Validation: Loss: 0.3929, Accuracy: 0.7500\n",
            "Validation Batch number: 010, Validation: Loss: 0.0010, Accuracy: 1.0000\n",
            "Validation Batch number: 011, Validation: Loss: 0.0051, Accuracy: 1.0000\n",
            "Validation Batch number: 012, Validation: Loss: 0.1614, Accuracy: 1.0000\n",
            "Validation Batch number: 013, Validation: Loss: 0.0010, Accuracy: 1.0000\n",
            "Validation Batch number: 014, Validation: Loss: 0.3870, Accuracy: 0.7500\n",
            "Validation Batch number: 015, Validation: Loss: 0.0395, Accuracy: 1.0000\n",
            "Validation Batch number: 016, Validation: Loss: 0.4579, Accuracy: 0.5000\n",
            "Validation Batch number: 017, Validation: Loss: 0.0072, Accuracy: 1.0000\n",
            "Validation Batch number: 018, Validation: Loss: 0.0004, Accuracy: 1.0000\n",
            "Validation Batch number: 019, Validation: Loss: 0.1981, Accuracy: 0.7500\n",
            "Validation Batch number: 020, Validation: Loss: 0.1020, Accuracy: 1.0000\n",
            "Validation Batch number: 021, Validation: Loss: 0.0054, Accuracy: 1.0000\n",
            "Validation Batch number: 022, Validation: Loss: 0.0001, Accuracy: 1.0000\n",
            "Validation Batch number: 023, Validation: Loss: 0.0180, Accuracy: 1.0000\n",
            "Validation Batch number: 024, Validation: Loss: 0.0305, Accuracy: 1.0000\n",
            "Validation Batch number: 025, Validation: Loss: 0.0056, Accuracy: 1.0000\n",
            "Validation Batch number: 026, Validation: Loss: 0.0073, Accuracy: 1.0000\n",
            "Validation Batch number: 027, Validation: Loss: 0.1999, Accuracy: 1.0000\n",
            "Validation Batch number: 028, Validation: Loss: 0.0181, Accuracy: 1.0000\n",
            "Validation Batch number: 029, Validation: Loss: 0.5273, Accuracy: 0.7500\n",
            "Validation Batch number: 030, Validation: Loss: 0.0347, Accuracy: 1.0000\n",
            "Validation Batch number: 031, Validation: Loss: 0.2824, Accuracy: 0.7500\n",
            "Validation Batch number: 032, Validation: Loss: 0.2860, Accuracy: 0.7500\n",
            "Validation Batch number: 033, Validation: Loss: 0.1172, Accuracy: 1.0000\n",
            "Validation Batch number: 034, Validation: Loss: 0.0013, Accuracy: 1.0000\n",
            "Validation Batch number: 035, Validation: Loss: 0.0013, Accuracy: 1.0000\n",
            "Validation Batch number: 036, Validation: Loss: 0.0142, Accuracy: 1.0000\n",
            "Epoch : 001, Training: Loss : 0.8890, Accuracy: 89.4074%\n",
            "Validation : Loss : 0.0946, Accuracy: 93.3333%, Time: 18.7813s\n",
            "model for epoch 1 saved\n",
            "Best accuracy achieved so far : 0.9333 on epoch 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "culacpOcgcUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "outputId": "b85d4c7d-99e9-4fff-fa3b-82d14aae8371"
      },
      "source": [
        "plotCost(history)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmqA9osy49ac",
        "colab_type": "text"
      },
      "source": [
        "Select the best model (i.e. the weights file saved on the max epoch) to test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEDTZ_VmkEK6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved_model = torch.load('src_model_1.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39gAloATgHQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7d017bf-d9bc-48ca-bee7-bfeb87b48067"
      },
      "source": [
        "computeTestSetAccuracy(saved_model, lossFunc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Batch number: 000, Test: Loss: 0.0002, Accuracy: 1.0000\n",
            "Test Batch number: 001, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 002, Test: Loss: 0.0155, Accuracy: 1.0000\n",
            "Test Batch number: 003, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 004, Test: Loss: 0.0035, Accuracy: 1.0000\n",
            "Test Batch number: 005, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 006, Test: Loss: 0.2503, Accuracy: 1.0000\n",
            "Test Batch number: 007, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 008, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 009, Test: Loss: 0.0569, Accuracy: 1.0000\n",
            "Test Batch number: 010, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 011, Test: Loss: 0.0013, Accuracy: 1.0000\n",
            "Test Batch number: 012, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 013, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 014, Test: Loss: 0.5569, Accuracy: 1.0000\n",
            "Test Batch number: 015, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 016, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 017, Test: Loss: 0.0005, Accuracy: 1.0000\n",
            "Test Batch number: 018, Test: Loss: 0.1652, Accuracy: 1.0000\n",
            "Test Batch number: 019, Test: Loss: 0.0002, Accuracy: 1.0000\n",
            "Test Batch number: 020, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 021, Test: Loss: 0.0002, Accuracy: 1.0000\n",
            "Test Batch number: 022, Test: Loss: 0.0035, Accuracy: 1.0000\n",
            "Test Batch number: 023, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 024, Test: Loss: 0.0065, Accuracy: 1.0000\n",
            "Test Batch number: 025, Test: Loss: 0.0766, Accuracy: 1.0000\n",
            "Test Batch number: 026, Test: Loss: 0.0028, Accuracy: 1.0000\n",
            "Test Batch number: 027, Test: Loss: 0.3821, Accuracy: 1.0000\n",
            "Test Batch number: 028, Test: Loss: 0.0756, Accuracy: 1.0000\n",
            "Test Batch number: 029, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 030, Test: Loss: 0.0012, Accuracy: 1.0000\n",
            "Test Batch number: 031, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 032, Test: Loss: 0.0069, Accuracy: 1.0000\n",
            "Test Batch number: 033, Test: Loss: 0.3370, Accuracy: 1.0000\n",
            "Test Batch number: 034, Test: Loss: 0.0015, Accuracy: 1.0000\n",
            "Test Batch number: 035, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 036, Test: Loss: 0.0001, Accuracy: 1.0000\n",
            "Test Batch number: 037, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 038, Test: Loss: 0.0189, Accuracy: 1.0000\n",
            "Test Batch number: 039, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 040, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 041, Test: Loss: 0.3586, Accuracy: 1.0000\n",
            "Test Batch number: 042, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 043, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 044, Test: Loss: 0.0184, Accuracy: 1.0000\n",
            "Test Batch number: 045, Test: Loss: 0.0010, Accuracy: 1.0000\n",
            "Test Batch number: 046, Test: Loss: 0.0002, Accuracy: 1.0000\n",
            "Test Batch number: 047, Test: Loss: 0.0003, Accuracy: 1.0000\n",
            "Test Batch number: 048, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 049, Test: Loss: 0.0001, Accuracy: 1.0000\n",
            "Test Batch number: 050, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 051, Test: Loss: 0.0229, Accuracy: 1.0000\n",
            "Test Batch number: 052, Test: Loss: 0.0012, Accuracy: 1.0000\n",
            "Test Batch number: 053, Test: Loss: 0.0356, Accuracy: 1.0000\n",
            "Test Batch number: 054, Test: Loss: 0.0002, Accuracy: 1.0000\n",
            "Test Batch number: 055, Test: Loss: 0.1281, Accuracy: 1.0000\n",
            "Test Batch number: 056, Test: Loss: 0.0110, Accuracy: 1.0000\n",
            "Test Batch number: 057, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 058, Test: Loss: 0.0049, Accuracy: 1.0000\n",
            "Test Batch number: 059, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 060, Test: Loss: 0.0036, Accuracy: 1.0000\n",
            "Test Batch number: 061, Test: Loss: 0.0312, Accuracy: 1.0000\n",
            "Test Batch number: 062, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 063, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 064, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 065, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 066, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 067, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 068, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 069, Test: Loss: 0.4173, Accuracy: 1.0000\n",
            "Test Batch number: 070, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 071, Test: Loss: 0.0004, Accuracy: 1.0000\n",
            "Test Batch number: 072, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 073, Test: Loss: 0.0005, Accuracy: 1.0000\n",
            "Test Batch number: 074, Test: Loss: 0.0009, Accuracy: 1.0000\n",
            "Test Batch number: 075, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 076, Test: Loss: 0.1644, Accuracy: 1.0000\n",
            "Test Batch number: 077, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 078, Test: Loss: 0.1252, Accuracy: 1.0000\n",
            "Test Batch number: 079, Test: Loss: 0.0005, Accuracy: 1.0000\n",
            "Test Batch number: 080, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 081, Test: Loss: 0.2907, Accuracy: 1.0000\n",
            "Test Batch number: 082, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 083, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 084, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 085, Test: Loss: 0.4695, Accuracy: 1.0000\n",
            "Test Batch number: 086, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 087, Test: Loss: 0.0012, Accuracy: 1.0000\n",
            "Test Batch number: 088, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 089, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 090, Test: Loss: 0.0049, Accuracy: 1.0000\n",
            "Test Batch number: 091, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 092, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 093, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 094, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 095, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 096, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 097, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 098, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 099, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 100, Test: Loss: 0.0009, Accuracy: 1.0000\n",
            "Test Batch number: 101, Test: Loss: 0.0225, Accuracy: 1.0000\n",
            "Test Batch number: 102, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 103, Test: Loss: 0.0416, Accuracy: 1.0000\n",
            "Test Batch number: 104, Test: Loss: 0.1483, Accuracy: 1.0000\n",
            "Test Batch number: 105, Test: Loss: 0.0008, Accuracy: 1.0000\n",
            "Test Batch number: 106, Test: Loss: 0.0342, Accuracy: 1.0000\n",
            "Test Batch number: 107, Test: Loss: 0.0010, Accuracy: 1.0000\n",
            "Test Batch number: 108, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 109, Test: Loss: 0.0004, Accuracy: 1.0000\n",
            "Test Batch number: 110, Test: Loss: 0.0093, Accuracy: 1.0000\n",
            "Test Batch number: 111, Test: Loss: 0.0004, Accuracy: 1.0000\n",
            "Test Batch number: 112, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 113, Test: Loss: 0.0000, Accuracy: 1.0000\n",
            "Test Batch number: 114, Test: Loss: 0.0156, Accuracy: 1.0000\n",
            "Test Batch number: 115, Test: Loss: 0.0016, Accuracy: 1.0000\n",
            "Test Batch number: 116, Test: Loss: 0.0001, Accuracy: 1.0000\n",
            "Test Batch number: 117, Test: Loss: 0.6926, Accuracy: 1.0000\n",
            "Test Batch number: 118, Test: Loss: 0.0181, Accuracy: 1.0000\n",
            "Test Batch number: 119, Test: Loss: 0.0030, Accuracy: 1.0000\n",
            "Test accuracy : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}